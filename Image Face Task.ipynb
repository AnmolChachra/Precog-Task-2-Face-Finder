{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "import math\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../Anmol/Desktop/ImageTask/AllFaces/Face2.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7c1cf2124a28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mSAVE_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../Anmol/Desktop/ImageTask/Arvind_Kejriwal_Pics/Face'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#IMG = Image.open(os.path.join(IMAGE_DIR,'1.jpg'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mIMAGE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../Anmol/Desktop/ImageTask/AllFaces'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Face2.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/cv/lib/python3.5/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mdocstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_dedent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_imread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2232\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2233\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_imread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/cv/lib/python3.5/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mext\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1280\u001b[0;31m         \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpilread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m             raise ValueError('Only know how to handle extensions: %s; '\n",
      "\u001b[0;32m~/.virtualenvs/cv/lib/python3.5/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mpilread\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m   1256\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1258\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1259\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpil_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/cv/lib/python3.5/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2530\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2531\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../Anmol/Desktop/ImageTask/AllFaces/Face2.jpg'"
     ]
    }
   ],
   "source": [
    "IMAGE_DIR = '../Anmol/Desktop/ImageTask/Arvind_Kejriwal_Pics/Only Face/'\n",
    "SAVE_DIR = '../Anmol/Desktop/ImageTask/Arvind_Kejriwal_Pics/Face'\n",
    "#IMG = Image.open(os.path.join(IMAGE_DIR,'1.jpg'))\n",
    "IMAGE = plt.imread(os.path.join('../Anmol/Desktop/ImageTask/AllFaces','Face2.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all(image_directory=None):\n",
    "    if image_directory==None:\n",
    "        image_directory = IMAGE_DIR\n",
    "    Images = []\n",
    "    count = 0\n",
    "    for img in tqdm(os.listdir(image_directory)):\n",
    "        count+=1\n",
    "        path = os.path.join(image_directory, img)\n",
    "        img = cv2.imread(path) #cv2 read images\n",
    "        cv2.imwrite(os.path.join(SAVE_DIR, str(count)+\".jpg\"),img)\n",
    "        Images.append(img)\n",
    "    return Images\n",
    "#fig, axes = plt.subplots(1,1,figsize=(16,16))\n",
    "#axes.imshow(IMAGE[:,:,0])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Images = extract_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make 4 image upsampled and 4 image downsampled + the actual image! 9 images of each image\n",
    "#os.mkdir('../Anmol/Desktop/ImageTask/Arvind_Kejriwal_Pics/SampledFaceImages')\n",
    "#os.mkdir('../Anmol/Desktop/ImageTask/Arvind_Kejriwal_Pics/HOGFaceImages')\n",
    "\n",
    "SAMPLED_SETS = '../Anmol/Desktop/ImageTask/Arvind_Kejriwal_Pics/SampledFaceImages'\n",
    "\n",
    "def sample_images(*images, source_dir=None, dest_dir=None,save_bool = False, upsample=True, upfactor=4, downsample=True, downfactor=4):  \n",
    "    upsampled_images = []\n",
    "    downsampled_images = []\n",
    "    if not(images) and not(source_dir):\n",
    "        print(\"No images to be upsampled! Please provide the images or define the source directory\")\n",
    "        \n",
    "    elif images and not(source_dir):\n",
    "        print(\"Sampling the image you provided\")\n",
    "        count = 0\n",
    "        if upsample:\n",
    "            print(\"--Performing Upsampling\")\n",
    "            for img in images:\n",
    "                count+=1\n",
    "                upsampled = img   \n",
    "                upsample_count = 0\n",
    "                for i in range(upfactor):\n",
    "                    upsample_count+=1\n",
    "                    upsampled = cv2.pyrUp(upsampled)\n",
    "                    upsampled_images.append(upsampled)\n",
    "                    if dest_dir!=None:\n",
    "                        cv2.imwrite(os.path.join(dest_dir,'image_'+str(count)+'_upsampled_'+str(upsample_count)+\".jpg\"),upsampled)\n",
    "                if dest_dir!=None:\n",
    "                    cv2.imwrite(os.path.join(dest_dir,'image_'+str(count)+\"normal.jpg\"),img)\n",
    "        \n",
    "        count = 0\n",
    "        \n",
    "        if downsample:\n",
    "            print(\"--Performing Downsampling\")\n",
    "            for img in images:\n",
    "                count+=1\n",
    "                downsample_count = 0\n",
    "                downsampled  = img\n",
    "                for i in range(downfactor):\n",
    "                    downsample_count+=1\n",
    "                    downsampled = cv2.pyrDown(downsampled)\n",
    "                    downsampled_images.append(downsampled)\n",
    "                    if dest_dir!=None:\n",
    "                        cv2.imwrite(os.path.join(dest_dir,'image_'+str(count)+'_downsampled_'+str(downsample_count)+\".jpg\"),downsampled)\n",
    "                if dest_dir!=None:\n",
    "                    if os.path.exists(os.path.join(dest_dir,'image_'+str(count)+\"normal.jpg\")):\n",
    "                        continue\n",
    "                    else:\n",
    "                        cv2.imwrite(os.path.join(dest_dir,'image_'+str(count)+\"normal.jpg\"),img)  \n",
    "        \n",
    "        \n",
    "        return upsampled_images, downsampled_images\n",
    "    \n",
    "    else:\n",
    "        print(\"Sampling from the source_dir that you provided :\") \n",
    "        if upsample:\n",
    "            print(\"--Performing Upsampling\")\n",
    "            count = 0\n",
    "            for img in os.listdir(source_dir):\n",
    "                path = os.path.join(source_dir,img)\n",
    "                Image = cv2.imread(path)\n",
    "                count+=1\n",
    "                upsampled = Image   \n",
    "                upsample_count = 0\n",
    "                for i in range(upfactor):\n",
    "                    upsample_count+=1\n",
    "                    upsampled = cv2.pyrUp(upsampled)\n",
    "                    upsampled_images.append(upsampled)\n",
    "                    if dest_dir!=None:\n",
    "                        cv2.imwrite(os.path.join(dest_dir,'image_'+str(count)+'_upsampled_'+str(upsample_count)+\".jpg\"),upsampled)\n",
    "                if dest_dir!=None:\n",
    "                    cv2.imwrite(os.path.join(dest_dir,'image_'+str(count)+\"normal.jpg\"),Image)\n",
    "                    \n",
    "        if downsample:\n",
    "            print(\"--Performing Downsampling\")\n",
    "            count = 0\n",
    "            for img in os.listdir(source_dir):\n",
    "                path = os.path.join(source_dir,img)\n",
    "                Image = cv2.imread(path)\n",
    "                count+=1\n",
    "                downsample_count = 0\n",
    "                downsampled  = Image\n",
    "                for i in range(downfactor):\n",
    "                    downsample_count+=1\n",
    "                    downsampled = cv2.pyrDown(downsampled)\n",
    "                    downsampled_images.append(downsampled)\n",
    "                    if dest_dir!=None:\n",
    "                        cv2.imwrite(os.path.join(dest_dir,'image_'+str(count)+'_downsampled_'+str(downsample_count)+\".jpg\"),downsampled)\n",
    "                \n",
    "                if dest_dir!=None:\n",
    "                    if os.path.exists(os.path.join(dest_dir,'image_'+str(count)+\"normal.jpg\")):\n",
    "                        continue\n",
    "                    else:\n",
    "                        cv2.imwrite(os.path.join(dest_dir,'image_'+str(count)+\"normal.jpg\"),Image)        \n",
    "      \n",
    "        return upsampled_images,downsampled_images \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No images to be upsampled! Please provide the images or define the source directory\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-9ae0a0c4a81c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "x,y = sample_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_faces_dir = '../Anmol/Desktop/ImageTask/AllFaces/'\n",
    "count = 0\n",
    "for folder in tqdm(os.listdir('../Anmol/Desktop/lfw/lfw/')):\n",
    "    for img in os.listdir(os.path.join('../Anmol/Desktop/lfw/lfw/',folder)):\n",
    "        count+=1\n",
    "        path = '../Anmol/Desktop/lfw/lfw/'+str(folder)+'//'+str(img)\n",
    "        image = cv2.imread(path)\n",
    "        cv2.imwrite(os.path.join(All_faces_dir,'Face'+str(count)+'.jpg'),image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run only once!!!!!!!!!!!!!\n",
    "\n",
    "\n",
    "Non_faces_dir = '../Anmol/Desktop/ImageTask/NonFaces'\n",
    "count = 0\n",
    "for img1, img2 in tqdm(zip(os.listdir('../Anmol/Desktop/jpg1.tar/jpg/'),os.listdir('../Anmol/Desktop/jpg2.tar/jpg/'))):\n",
    "    if img1!=None and img2!=None:\n",
    "        count+=1\n",
    "        path1 = '../Anmol/Desktop/jpg1.tar/jpg/'+str(img1)\n",
    "        path2 = '../Anmol/Desktop/jpg2.tar/jpg/'+str(img2)            \n",
    "        image1 = cv2.imread(path1)\n",
    "        image2 = cv2.imread(path2)\n",
    "        cv2.imwrite(os.path.join(Non_faces_dir,'NoFace'+str(count)+'.jpg'),image1)\n",
    "        count+=1\n",
    "        cv2.imwrite(os.path.join(Non_faces_dir,'NoFace'+str(count)+'.jpg'),image2)\n",
    "        \n",
    "    elif img1==None and img2!=None:\n",
    "        print(\"count = \",count)\n",
    "        path = '../Anmol/Desktop/jpg2.tar/jpg/'+str(img2)\n",
    "        image = cv2.imread(path)\n",
    "        cv2.imwrite(os.path.join(Non_faces_dir,'NoFace'+str(count)+'.jpg'),image)\n",
    "        \n",
    "    elif img2==None and img1!=None:\n",
    "        path = '../Anmol/Desktop/jpg2.tar/jpg/'+str(img1)\n",
    "        image = cv2.imread(path)\n",
    "        cv2.imwrite(os.path.join(Non_faces_dir,'NoFace'+str(count)+'.jpg'),image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hog_images(*sampled_images,source_dir = None, dest_dir = None):\n",
    "    hog_images = []\n",
    "    if not(sampled_images):\n",
    "        if source_dir and os.path.exists(source_dir):\n",
    "            sampled_images = sample_images(source_dir)\n",
    "        else:\n",
    "            print(\"No images provided and the path entered does not exist\")\n",
    "    else:\n",
    "        upsampled_images,downsampled_images = sampled_images[0]\n",
    "            \n",
    "    for img in tqdm(os.listdir(source_dir)):\n",
    "        image = cv2.imread(os.path.join(source_dir, img))\n",
    "        fd, hog_image = hog(image[:,:,0], orientations=8, pixels_per_cell=(16, 16),cells_per_block=(1, 1),visualise=True)\n",
    "        # Rescale histogram for better display\n",
    "        hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
    "        hog_images.append(hog_image_rescaled)\n",
    "        cv2.imwrite(os.path.join(HOG_SETS,os.path.join(dest_dir,img)))\n",
    "    return hog_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|████████████████████████████▋                                               | 4995/13233 [00:30<00:49, 166.32it/s]"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "hog_face_images = []\n",
    "hog_face_descriptors = []\n",
    "source_dir = '../Anmol/Desktop/ImageTask/AllFaces/'\n",
    "count = 0\n",
    "winSize = (100,100)\n",
    "blockSize = (15,15)\n",
    "blockStride = (5,5)\n",
    "cellSize = (5,5)\n",
    "nbins = 9\n",
    "for img in tqdm(os.listdir(source_dir)):    \n",
    "    if count==5000:\n",
    "        break\n",
    "    count+=1\n",
    "    image = cv2.imread(os.path.join(source_dir, img))\n",
    "    img1 = cv2.resize(image,(100,100))\n",
    "    hog = cv2.HOGDescriptor(winSize,blockSize,blockStride,cellSize,nbins)\n",
    "    try:\n",
    "        h = hog.compute(img1)\n",
    "    except:\n",
    "        print(\"oh no\")\n",
    "        continue    \n",
    "    hog_face_descriptors.append(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(186624, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.02467235]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " ..., \n",
      " [ 0.00253962]\n",
      " [ 0.02031944]\n",
      " [ 0.08503421]]\n"
     ]
    }
   ],
   "source": [
    "print(hog_face_descriptors[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                                                         | 0/1346 [00:00<?, ?it/s]\n",
      "  0%|                                                                                 | 1/1346 [00:00<04:54,  4.57it/s]\n",
      "  0%|▏                                                                                | 3/1346 [00:00<04:08,  5.40it/s]\n",
      "  0%|▎                                                                                | 5/1346 [00:00<03:29,  6.41it/s]\n",
      "  1%|▍                                                                                | 7/1346 [00:00<03:04,  7.26it/s]\n",
      "  1%|▌                                                                                | 9/1346 [00:00<02:43,  8.15it/s]\n",
      "  1%|▌                                                                               | 10/1346 [00:01<02:39,  8.36it/s]\n",
      "  1%|▋                                                                               | 11/1346 [00:01<02:38,  8.45it/s]\n",
      "  1%|▊                                                                               | 13/1346 [00:01<02:24,  9.24it/s]\n",
      "  1%|▉                                                                               | 15/1346 [00:01<02:08, 10.38it/s]\n",
      "  1%|█                                                                               | 17/1346 [00:01<02:45,  8.04it/s]\n",
      "  1%|█▏                                                                              | 19/1346 [00:02<03:01,  7.30it/s]\n",
      "  1%|█▏                                                                              | 20/1346 [00:02<02:56,  7.52it/s]\n",
      "  2%|█▏                                                                              | 21/1346 [00:02<03:54,  5.65it/s]\n",
      "  2%|█▎                                                                              | 22/1346 [00:02<03:45,  5.88it/s]\n",
      "  2%|█▎                                                                              | 23/1346 [00:03<04:35,  4.80it/s]\n",
      "  2%|█▍                                                                              | 24/1346 [00:03<04:06,  5.36it/s]\n",
      "  2%|█▍                                                                              | 25/1346 [00:03<04:03,  5.42it/s]\n",
      "  2%|█▌                                                                              | 26/1346 [00:03<04:41,  4.70it/s]\n",
      "  2%|█▌                                                                              | 27/1346 [00:03<04:24,  4.99it/s]\n",
      "  2%|█▋                                                                              | 28/1346 [00:04<04:53,  4.49it/s]\n",
      "  2%|█▋                                                                              | 29/1346 [00:04<04:26,  4.95it/s]\n",
      "  2%|█▊                                                                              | 30/1346 [00:04<05:10,  4.24it/s]\n",
      "  2%|█▊                                                                              | 31/1346 [00:04<04:29,  4.88it/s]\n",
      "  2%|█▉                                                                              | 32/1346 [00:05<05:01,  4.35it/s]\n",
      "  2%|█▉                                                                              | 33/1346 [00:05<04:21,  5.02it/s]\n",
      "  3%|██                                                                              | 34/1346 [00:05<04:36,  4.74it/s]\n",
      "  3%|██                                                                              | 35/1346 [00:05<04:03,  5.37it/s]\n",
      "  3%|██▏                                                                             | 37/1346 [00:05<03:59,  5.46it/s]\n",
      "  3%|██▎                                                                             | 38/1346 [00:05<03:43,  5.85it/s]\n",
      "  3%|██▎                                                                             | 39/1346 [00:06<04:14,  5.14it/s]\n",
      "  3%|██▍                                                                             | 40/1346 [00:06<03:47,  5.73it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1346/1346 [02:51<00:00,  7.86it/s]\n"
     ]
    }
   ],
   "source": [
    "hog_non_face_images = []\n",
    "hog_non_face_descriptors = []\n",
    "source_dir2 = '../Anmol/Desktop/ImageTask/NonFaces'\n",
    "for img in tqdm(os.listdir(source_dir2)):    \n",
    "    image = cv2.imread(os.path.join(source_dir2, img))\n",
    "    img1 = cv2.resize(image,(100,100))\n",
    "    hog = cv2.HOGDescriptor(winSize,blockSize,blockStride,cellSize,nbins)\n",
    "    try:\n",
    "        h = hog.compute(img1)\n",
    "    except:\n",
    "        print(\"oh no\")\n",
    "        continue    \n",
    "    hog_non_face_descriptors.append(h)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hog_nf_descriptors = []\n",
    "hog_f_descriptors = []\n",
    "for i in hog_non_face_descriptors:\n",
    "    new1 = i.reshape(-1)\n",
    "    hog_nf_descriptors.append(new1)\n",
    "for i in hog_face_descriptors:\n",
    "    new2 = i.reshape(-1)\n",
    "    hog_f_descriptors.append(new2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.        ,  0.        , ...,  0.19093782,\n",
       "        0.06745495,  0.04441716], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hog_nf_descriptors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "hog_nf_descriptors = []\n",
    "hog_f_descriptors = []\n",
    "with open(\"../Anmol/Desktop/ImageTask/hog_face_descriptors3.pickle\",'rb') as f:\n",
    "     hog_f_descriptors=pickle.load(f)\n",
    "with open(\"../Anmol/Desktop/ImageTask/hog_non_face_descriptors3.pickle\",'rb') as f:\n",
    "     hog_nf_descriptors=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.array(hog_non_face_images)\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_labels = []\n",
    "non_face_labels = []\n",
    "for i in range(len(hog_f_descriptors)):\n",
    "    face_labels.append(1)\n",
    "for i in range(len(hog_nf_descriptors)):\n",
    "    non_face_labels.append(0)\n",
    "\n",
    "X = hog_f_descriptors + hog_nf_descriptors\n",
    "Y = face_labels+non_face_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "rs = ShuffleSplit(n_splits=1,train_size=0.8,test_size=0.2,random_state=1)\n",
    "Xtrain = []\n",
    "Ytrain = []\n",
    "Xtest = []\n",
    "Ytest = []\n",
    "for trainX,testX in rs.split(X):\n",
    "    for i in trainX:\n",
    "        Xtrain.append(X[i])\n",
    "    for i in testX:\n",
    "        Xtest.append(X[i])\n",
    "for trainY,testY in rs.split(Y):\n",
    "    for i in trainY:\n",
    "        Ytrain.append(Y[i])\n",
    "    for i in testX:\n",
    "        Ytest.append(Y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restarted\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "print(\"restarted\")\n",
    "svm = cv2.ml.SVM_create()\n",
    "svm.setType(cv2.ml.SVM_C_SVC)\n",
    "svm.setKernel(cv2.ml.SVM_LINEAR)\n",
    "#Xtrain_temp = Xtrain.reshape((Xtrain.shape[1], Xtrain.shape[0]))\n",
    "#Ytrain_temp = Ytrain.reshape((1,Ytrain.shape[0]))\n",
    "svm.train(np.array(Xtrain,dtype=np.float32),0,np.array(list(Ytrain),dtype=np.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.save(\"../Anmol/Desktop/svm3.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.3339921689312964\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import re\n",
    "tree = ET.parse('../Anmol/Desktop/svm3.xml')\n",
    "root = tree.getroot()\n",
    "SVs = root.getchildren()[0].getchildren()[-2].getchildren()[0] \n",
    "rho = float( root.getchildren()[0].getchildren()[-1].getchildren()[0].getchildren()[1].text )\n",
    "svmvec = [float(x) for x in re.sub( '\\s+', ' ', SVs.text ).strip().split(' ')]\n",
    "svmvec.append(-rho)\n",
    "pickle.dump(svmvec, open(\"../Anmol/Desktop/svm3.pickle\", 'wb'))\n",
    "print(svmvec[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3339921689312964\n"
     ]
    }
   ],
   "source": [
    "(rho, alpha, supportVectorIndices) = svm.getDecisionFunction(0)\n",
    "supportVectors = svm.getSupportVectors().ravel() \n",
    "supportVectors = np.append(supportVectors, -rho)\n",
    "print(rho)\n",
    "pickle.dump(supportVectors, open(\"../Anmol/Desktop/svm3.pickle\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "restart\n",
      "(225724644, 1)\n",
      "[ 2.54074236]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "print(\"restart\")\n",
    "winSize = (100,100)\n",
    "blockSize = (15,15)\n",
    "blockStride = (5,5)\n",
    "cellSize = (5,5)\n",
    "nbins = 9\n",
    "hog = cv2.HOGDescriptor(winSize,blockSize,blockStride,cellSize,nbins)\n",
    "svm = pickle.load(open(\"../Anmol/Desktop/svm3.pickle\",'rb'))\n",
    "hog.setSVMDetector(np.array(svm))\n",
    "del svm\n",
    "Image = cv2.imread('../Anmol/Desktop/114.jpg')\n",
    "orig = Image.copy()\n",
    "u = hog.compute(Image)\n",
    "print(u.shape)\n",
    "rects = []\n",
    "(rects, weights) = hog.detectMultiScale(Image, winStride=(10, 10),scale=1.05)\n",
    "print(weights[0])\n",
    "# draw the original bounding boxes\n",
    "for (x, y, w, h) in rects:\n",
    "    cv2.rectangle(orig, (x, y), (x + w, y + h),(0,0,255),3)\n",
    "\n",
    "# fairly large overlap threshold to try to maintain overlapping\n",
    "# boxes that are still people\n",
    "rects = np.array([[x, y, x + w, y + h] for (x, y, w, h) in rects])\n",
    "#pick = non_max_suppression(rects, probs=None, overlapThresh=0.65)\n",
    " \n",
    "# draw the final bounding boxes\n",
    "for (xA, yA, xB, yB) in rects:\n",
    "    cv2.rectangle(Image, (xA, yA), (xB, yB), (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow(\"Before NMS\", orig)\n",
    "cv2.imshow(\"After NMS\", Image)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "sub_count = 0\n",
    "path = 'srk.jpg'\n",
    "image = cv2.imread(path)\n",
    "try:\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "except:\n",
    "    pass\n",
    "    \n",
    "faces = face_cascade.detectMultiScale(gray, 1.1, 5)\n",
    "\n",
    "for (x,y,w,h) in faces:  \n",
    "    sub_count+=1\n",
    "    cv2.imwrite('pic_rectangles/'+str(sub_count)+\".jpg\",image[y:y+h,x:x+h,:])\n",
    "    \n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(image,(x,y),(x+w,y+h),(255,255,0),2)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = image[y:y+h, x:x+w]\n",
    "    cv2.imwrite('Faces Detected/'+str(path),image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "winSize = (250,250)\n",
    "blockSize = (10,10)\n",
    "blockStride = (10,10)\n",
    "cellSize = (1,1)\n",
    "nbins = 1\n",
    "hog = cv2.HOGDescriptor(winSize,blockSize,blockStride,cellSize,nbins)\n",
    "try:\n",
    "    h = hog.compute(img1)\n",
    "except:\n",
    "    print(\"oh no\")\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "svmc = svm.SVC()\n",
    "Xtrain = np.array(Xtrain)\n",
    "Xtrain = Xtrain.reshape((Xtrain.shape[0],-1))\n",
    "#svmc.fit(Xtrain,Ytrain)\n",
    "print(Xtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain = np.array(Ytrain)\n",
    "svmc.fit(Xtrain,Ytrain)\n",
    "Ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../Anmol/Desktop/ImageTask/svmc_model.sav','wb') as f:\n",
    "    pickle.dump(svmc,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest=  np.array(Xtest)\n",
    "Xtest = Xtest.reshape((Xtest.shape[0],-1))\n",
    "Ypredict = svmc.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "actual_yes = sum(Ytest)\n",
    "actual_no = len(Ytest) - actual_yes\n",
    "predicted_yes = 0\n",
    "predicted_no = 0\n",
    "true_positives = 0\n",
    "false_positives = 0\n",
    "true_negatives = 0\n",
    "false_negatives = 0\n",
    "for i in range(len(Ytest)):\n",
    "    if Ytest[i]==Ypredict[i] and Ytest[i]==1:\n",
    "        true_positives+=1\n",
    "    elif Ytest[i]!=Ypredict[i] and Ypredict[i]==1:\n",
    "        false_positives+=1\n",
    "    elif Ytest[i]!=Ypredict[i] and Ypredict[i]==0:\n",
    "        false_negatives+=1\n",
    "    elif Ytest[i]==Ypredict[i] and Ytest[i]==0:\n",
    "        true_negatives+=1\n",
    "print(true_positives,false_positives, true_negatives, false_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import hog\n",
    "Image = cv2.imread('../Anmol/Desktop/114.jpg')\n",
    "img1 = cv2.resize(Image,(250,250))\n",
    "fd, hog_image = hog(img1[:,:,0], orientations=1, pixels_per_cell=(10, 10),cells_per_block=(1, 1),visualise=True)\n",
    "    # Rescale histogram for better display\n",
    "hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10))\n",
    "hog_image_rescaled = hog_image_rescaled.reshape((62500,1))\n",
    "hog_image_rescaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i in range(len(hog_image_rescaled)):\n",
    "    if hog_image_rescaled[i] in h:\n",
    "        count+=1\n",
    "print(count)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image = hog_image_rescaled.reshape(-1)\n",
    "svmc.predict(test_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,16))\n",
    "ax.imshow(hog_image_rescaled[50:300,300:600],cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anmolvm",
   "language": "python",
   "name": "anmolvm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
